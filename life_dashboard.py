"""
ç·åˆãƒ©ã‚¤ãƒ•ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Obsidianæ—¥è¨˜ã‹ã‚‰ç¡çœ ãƒ»ç­‹ãƒˆãƒ¬ãƒ»æ­©æ•°ãƒ»èª­æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€
HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ + Obsidianãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹

ä½¿ã„æ–¹:
  python life_dashboard.py            # ç”Ÿæˆã®ã¿
  python life_dashboard.py --deploy   # ç”Ÿæˆ + GitHub Pagesã«ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import re
import json
import sys
import os
import subprocess
import argparse
from pathlib import Path
from datetime import datetime, timedelta

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# === è¨­å®š ===
DIARY_DIR = Path(r"C:\Documents\Obsidian Vault\Main Vault\æ—¥è¨˜")
VAULT_DIR = Path(r"C:\Documents\Obsidian Vault\Main Vault")
SCRIPT_DIR = Path(__file__).parent
DOCS_DIR = SCRIPT_DIR / "docs"

# å…¨è§’æ•°å­—â†’åŠè§’
ZEN_TO_HAN = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789')

def zen_to_int(s: str) -> int:
    """å…¨è§’æ•°å­—ã‚’å«ã‚€æ–‡å­—åˆ—ã‹ã‚‰æ•´æ•°ã‚’å–å¾—"""
    s = s.translate(ZEN_TO_HAN)
    m = re.search(r'(\d+)', s)
    return int(m.group(1)) if m else 0


def parse_frontmatter(text: str) -> dict:
    fm = {}
    if not text.startswith("---"):
        return fm
    end = text.find("---", 3)
    if end == -1:
        return fm
    block = text[3:end].strip()
    for line in block.splitlines():
        line = line.strip()
        if line.startswith("-") or not line:
            continue
        if ":" in line:
            key, _, val = line.partition(":")
            fm[key.strip()] = val.strip().strip('"').strip("'")
    return fm


def parse_duration(s: str) -> float:
    hours, mins = 0, 0
    hm = re.search(r'(\d+)\s*æ™‚é–“', s)
    if hm: hours = int(hm.group(1))
    mm = re.search(r'(\d+)\s*åˆ†', s)
    if mm: mins = int(mm.group(1))
    return hours + mins / 60


def parse_sleep_details(text: str) -> dict:
    d = {}
    m = re.search(r'ç¡çœ ã‚¹ã‚³ã‚¢[ï¼š:]?\s*(\d+)', text)
    if m: d['score'] = int(m.group(1))

    m = re.search(r'æ·±ã„\s*([\dæ™‚é–“åˆ†]+)', text)
    if m: d['deep'] = round(parse_duration(m.group(1)), 2)
    m = re.search(r'ãƒ©ã‚¤ãƒˆ\s*([\dæ™‚é–“åˆ†]+)', text)
    if m: d['light'] = round(parse_duration(m.group(1)), 2)
    m = re.search(r'ãƒ¬ãƒ \s*([\dæ™‚é–“åˆ†]+)', text)
    if m: d['rem'] = round(parse_duration(m.group(1)), 2)
    m = re.search(r'è¦šé†’\s*([\dæ™‚é–“åˆ†]+)', text)
    if m: d['awake'] = round(parse_duration(m.group(1)), 2)

    m = re.search(r'å°±å¯\s*(\d{1,2}:\d{2})\s*[ã€œ~ï½]\s*èµ·åºŠ\s*(\d{1,2}:\d{2})', text)
    if m:
        d['bedtime'] = m.group(1)
        d['waketime'] = m.group(2)
    else:
        m = re.search(r'(\d{1,2}:\d{2})\s*[ã€œ~ï½]\s*(\d{1,2}:\d{2})', text)
        if m:
            d['bedtime'] = m.group(1)
            d['waketime'] = m.group(2)

    m = re.search(r'å¤©æ°—::(.+)', text)
    if m:
        weather = re.split(r'[ã€‚ã€\.!ï¼]', m.group(1).strip())[0].strip()
        d['weather'] = weather

    m = re.search(r'æ°—åˆ†::(.+)', text, re.DOTALL)
    if m:
        # Get full mood text (multi-line until next section)
        mood_raw = m.group(1).strip()
        # Cut at next section header
        cut = re.search(r'\n-\s+\S+::', mood_raw)
        if cut:
            mood_raw = mood_raw[:cut.start()].strip()
        d['mood'] = mood_raw

    m = re.search(r'æ­©æ•°::\s*([\d,]+)\s*æ­©', text)
    if m: d['steps'] = int(m.group(1).replace(',', ''))

    return d


def parse_exercise(fm: dict) -> dict:
    ex = {}
    for key, field in [('ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆ', 'squat'), ('è…¹ç­‹', 'abs'), ('è…•ç«‹ã¦ä¼ã›', 'pushup')]:
        val = fm.get(key, '')
        if val:
            ex[field] = zen_to_int(val)
    return ex


def parse_reading(text: str) -> list:
    books = []
    in_reading = False
    for line in text.splitlines():
        if 'ä»Šæ—¥èª­ã‚“ã æœ¬' in line or 'ğŸ“š' in line:
            in_reading = True
            continue
        if in_reading:
            if line.strip().startswith('#') or (line.strip() and not line.strip().startswith('-')):
                break
            m = re.search(r'\[\[(.+?)(?:\|.+?)?\]\]', line)
            if m:
                title = m.group(1)
                finished = 'èª­äº†' in line
                books.append({'title': title, 'finished': finished})
    return books


# === ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ ===

GENRE_RULES = [
    # (ã‚¸ãƒ£ãƒ³ãƒ«å, è‘—è€…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰, ã‚¿ã‚¤ãƒˆãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰)
    ('ãƒŸã‚¹ãƒ†ãƒªãƒ¼', ['é“å°¾ç§€ä»‹','æ±é‡åœ­å¾','ä»Šæ‘æ˜Œå¼˜','é˜¿æ´¥å·è¾°æµ·','æˆ‘å­«å­æ­¦ä¸¸','æµ¦è³€å’Œå®',
                    'è© å‚é›„äºŒ','ä¼¼é³¥é¶','æ±å·ç¯¤å“‰','è¥¿å¼è±Š','è¥¿å¼ è±Š','è¥¿æ¾¤ä¿å½¦','äº”ååµå¾‹äºº',
                    'æ½®è°·é¨“','å¤§å±±èª ä¸€éƒ','çŸ¥å¿µå®Ÿå¸Œäºº','ä¸‰æ—¥å¸‚é›¶','æ‘ä¸Šæš¢','æ—©å‚å',
                    'ç´ºé‡å¤©é¾','ç¥æ°¸å­¦','èª‰ç”°å“²ä¹Ÿ','ä½ç”°ç¥','å°å€‰åƒæ˜','ç”°æ‘å’Œå¤§',
                    'ã‚¯ãƒ¬ã‚¤ãƒ´ãƒ³','ãƒ•ãƒªãƒ¼ãƒ€','æ¢¨'], 
                   ['æ®ºäºº','ãƒŸã‚¹ãƒ†ãƒªãƒ¼','å¯†å®¤','æ¢åµ','å…«é›²','JãƒŸã‚¹ãƒ†ãƒªãƒ¼','ã‚«ãƒ©ã‚¹ã®è¦ªæŒ‡',
                    'ã‚«ã‚¨ãƒ«ã®å°æŒ‡','ãƒã‚¹ã‚«ãƒ¬ãƒ¼ãƒ‰','ãƒ­ãƒ³ãƒ‰','Another','ï¼¡ï¼®ï¼¯ï¼´ï¼¨ï¼¥ï¼²ï¼³ã®æ®ºäºº',
                    'ã‚·ãƒ³ãƒ‡ãƒ¬ãƒ©åŸ','ãƒã‚¦ã‚¹ãƒ¡ã‚¤ãƒ‰','æ“ã‚‹ç”·','äº¡éœŠ','ä»•æ›å³¶','ãƒ©ãƒƒãƒˆãƒãƒ³',
                    'å¾©è®ã¯','ç¡å­ã®å¡”','ç™½é·ºç«‹ã¤','ãƒ‡ã‚¹ãƒã‚§ã‚¢','å˜˜ã¤ã','å…‡äººé‚¸',
                    'é€æ˜äººé–“ã¯å¯†å®¤','ä¸åœ¨ã®ç”Ÿå­˜è¨¼æ˜','è¿·å®®ç‰¢','æ¨ç†å¤§æˆ¦','è£ãçœ¼',
                    'ã«ã„ãŸã‚‹ç—…','èº«ã‹ã‚‰å‡ºãŸé—‡','æ™‚ç©ºçŠ¯','å¹»å‘Š']),
    ('ä»æ•™ãƒ»å®—æ•™', ['æ¢¶å±±é›„ä¸€','å››å¤·æ³•é¡•','èŠåœ°ç« å¤ª','ç„ä¾‘å®—ä¹…','å¹³é›…è¡Œ'],
                   ['ä»æ•™','æµ„åœŸ','è¼ªå»»','è¯å³','éŒå€‰ä»æ•™','å„’æ•™','é“æ•™','æ¶…æ§ƒ','è¡†ç”Ÿ']),
    ('ãƒ›ãƒ©ãƒ¼ãƒ»æ€ªå¥‡', ['èƒŒç­‹','å°æ¾å·¦äº¬','å°æ¾ å·¦äº¬'],
                     ['ææ€–','ï¼³ï¼¦','ç‰›ã®é¦–','ãƒ›ãƒ©ãƒ¼','å¿ƒéœŠ']),
    ('è‡ªå·±å•“ç™ºãƒ»å­¦ç¿’', ['æ¨ºæ²¢ç´«è‹‘','æ¦æœ¬åšæ˜','çŸ³ç”°å…‰è¦','å¾³è°·æ™ºå²','äº•ä¸Šæ…å¹³','è¥¿å²¡å£±èª ',
                       'ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³','å±±å£ å‘¨','å±±å£å‘¨','ã‚µãƒ«ãƒãƒ³ãƒ»ã‚«ãƒ¼ãƒ³','å…«æœ¨','ã‚­ãƒ ãƒ»ã‚¤ãƒƒã‚«ãƒ³',
                       'ã‚¢ãƒ€ãƒ ãƒ»ã‚°ãƒ©ãƒ³ãƒˆ','å¤§å¡šã‚ã¿','å‡ºå£æ²»æ˜','æ¯›å†…æ‹¡'],
                      ['å‹‰å¼·','é›†ä¸­åŠ›','å…¨åŠ›åŒ–','è‡ªå·±æˆé•·','çµŒå–¶','HIDDEN','èª­æ›¸ã‚’ä»•äº‹',
                       'èª­æ›¸ã™ã‚‹è„³','100æ—¥ãƒãƒ£ãƒ¬ãƒ³ã‚¸','ä¸–ç•Œä¸€ã‚†ã‚‹ã„','å·¨äººã®ãƒãƒ¼ãƒˆ',
                       'ã‚»ã‚«ãƒ³ãƒ‰ãƒ»ãƒãƒ£ãƒ³ã‚¹','å¯èƒ½æ€§ã®ç§‘å­¦']),
    ('å¥åº·ãƒ»ç§‘å­¦', ['æ± ç”°å…‰å²','çŸ³å·æ³°å¼˜','æ±å³¶å¨å²','ç¨²è‘‰ä¿Šéƒ','ãƒªãƒ¼ãƒãƒ¼ãƒãƒ³'],
                   ['æ­©ã','ç¡çœ ','ä¸å¤œè„³','é‹å‹•ã®ç§‘å­¦','ãƒ¡ãƒ‡ã‚£ã‚¹ãƒ³','ãã£ã™ã‚Šçœ ã‚Œã‚‹']),
    ('ç¤¾ä¼šãƒ»ãƒãƒ³ãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³', ['ãƒ‘ã‚ªãƒ­','å¯Œæ°¸äº¬å­','å®®ä¸‹è‹±æ¨¹','å¤§åŸé“å‰‡','ã‚ªãƒ¼ãƒ‰ãƒªãƒ¼','æé›…å¿'],
                              ['ç¤¾ä¼š','ãƒ˜ãƒ³ãªã®','ãªãœç¤¾ä¼š','å¤ä»£æ–‡å­—','æ­´å²','è½ã¨ã—ç©´',
                               'å®…å»ºå£«']),
]

def classify_genre(title: str) -> str:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æ¨å®š"""
    for genre, authors, keywords in GENRE_RULES:
        for kw in keywords:
            if kw in title:
                return genre
        for author in authors:
            if author in title:
                return genre
    # ãƒ†ãƒ¼ãƒæ€§ã®ã‚ã‚‹å°èª¬
    if re.search(r'[å°èª¬|ç‰©èª|æ–‡åº«]', title):
        return 'ãã®ä»–å°èª¬'
    return 'ãã®ä»–'


def get_returned_titles() -> set:
    """ã‚¨ã‚¯ã‚»ãƒ«ã‹ã‚‰è¿”å´æ¸ˆã¿ï¼†æœªèª­äº†ã®æœ¬ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    excel_path = Path(r"C:\Users\trexa\OneDrive\è¨˜éŒ²\å›³æ›¸é¤¨ã«ã¦å€Ÿã‚ŠãŸæœ¬ã®è¨˜éŒ².xlsx")
    if not excel_path.exists():
        return set()
    try:
        import openpyxl
        wb = openpyxl.load_workbook(str(excel_path), data_only=True)
        returned_not_finished = set()
        for name in wb.sheetnames:
            ws = wb[name]
            for row in range(2, ws.max_row + 1):
                title = ws.cell(row, 3).value
                returned = ws.cell(row, 8).value
                finished = ws.cell(row, 9).value
                if title and returned and str(returned).strip() == '\u2714':
                    if not (finished and str(finished).strip() == '\u2714'):
                        returned_not_finished.add(title.strip())
        return returned_not_finished
    except Exception as e:
        print(f"   âš ï¸ ã‚¨ã‚¯ã‚»ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return set()


def build_reading_summary(data: list[dict]) -> dict:
    """å…¨æ—¥è¨˜ã‹ã‚‰èª­æ›¸ã‚µãƒãƒªãƒ¼ã‚’æ§‹ç¯‰ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ»ãƒšãƒ¼ã‚¹åˆ†æï¼‰"""
    book_tracker = {}  # title -> {first, last, finished, days_seen, genre}
    
    for entry in data:
        date_str = entry['date']
        for b in entry.get('books', []):
            title = b['title']
            if title not in book_tracker:
                book_tracker[title] = {
                    'title': title,
                    'first': date_str,
                    'last': date_str,
                    'finished': None,
                    'days_seen': 0,
                    'genre': classify_genre(title),
                }
            book_tracker[title]['last'] = date_str
            book_tracker[title]['days_seen'] += 1
            if b.get('finished'):
                book_tracker[title]['finished'] = date_str
    
    # è¿”å´æ¸ˆã¿ï¼†æœªèª­äº†ã®æœ¬ã‚’é™¤å¤–
    returned = get_returned_titles()
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªæ¸ˆã¿è¿”å´æœ¬ï¼ˆã‚¨ã‚¯ã‚»ãƒ«ã«ãªã„åˆ†ï¼‰
    manual_returned = {'ã‚ªãƒ¼ãƒ‰ãƒªãƒ¼ãƒ»ã‚¿ãƒ³ã®æ¯', 'æ–°ã‚¢ã‚¸ã‚¢ä»æ•™å²', 'ä¸å¯è§¦æ°‘ã¨ç¾ä»£ã‚¤ãƒ³ãƒ‰',
                       'åˆ—å³¶å‰µä¸–è¨˜', 'æ—¥æœ¬ã®æ­´å²1', 'æ—¥æœ¬ã®æ­´å²2', 'æ—¥æœ¬å²ã‚’å®—æ•™ã§èª­ã¿ãªãŠã™',
                       'ä»Šæ—¥ã®å­¦ã³', 'ğŸ“’èª­æ›¸ãƒãƒ¼ãƒˆ', 'è²·ã†é£Ÿæ–™ãƒ»æ—¥ç”¨å“', 'æ¬²ã—ã„ã‚‚ã®', 'ã™ã‚‹ã“ã¨',
                       'ã‚»ã‚«ãƒ³ãƒ‰ãƒ»ãƒãƒ£ãƒ³ã‚¹', 'ç•°æ¬¡å…ƒç·©å’Œã®ç½ªã¨ç½°', 'åˆã‚ã¦ã®ãƒãƒ«ã‚¯ã‚¹'}
    for b in list(book_tracker.values()):
        if not b['finished']:
            title_short = b['title'].split(' - ')[0]
            # Manual exclusion check
            for mr in manual_returned:
                if mr in title_short or title_short in mr:
                    b['returned'] = True
                    break
            if b.get('returned'):
                continue
            # Excel return check (improved matching)
            for rt in returned:
                if (title_short[:6] in rt or rt[:6] in title_short
                        or title_short in rt or rt in title_short):
                    b['returned'] = True
                    break
    
    # ãƒšãƒ¼ã‚¹è¨ˆç®—
    all_books = [b for b in book_tracker.values() if not b.get('returned')]
    for b in all_books:
        if b['finished']:
            d1 = datetime.strptime(b['first'], '%Y-%m-%d')
            d2 = datetime.strptime(b['finished'], '%Y-%m-%d')
            b['reading_days'] = (d2 - d1).days + 1
        else:
            b['reading_days'] = None
    
    # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥é›†è¨ˆ
    genre_counts = {}
    genre_finished = {}
    for b in all_books:
        g = b['genre']
        genre_counts[g] = genre_counts.get(g, 0) + 1
        if b['finished']:
            genre_finished[g] = genre_finished.get(g, 0) + 1
    
    # æœˆåˆ¥ã‚¸ãƒ£ãƒ³ãƒ«èª­äº†
    monthly_genre = {}
    for b in all_books:
        if b['finished']:
            m = b['finished'][:7]
            if m not in monthly_genre:
                monthly_genre[m] = {}
            g = b['genre']
            monthly_genre[m][g] = monthly_genre[m].get(g, 0) + 1
    
    # ãƒšãƒ¼ã‚¹çµ±è¨ˆ
    paces = [b['reading_days'] for b in all_books if b['reading_days'] is not None]
    avg_pace = sum(paces) / len(paces) if paces else 0
    
    returned_count = sum(1 for b in book_tracker.values() if b.get('returned'))
    print(f"   ğŸ“• è¿”å´æ¸ˆã¿ï¼ˆæœªèª­äº†ï¼‰é™¤å¤–: {returned_count}å†Š")
    
    return {
        'books': all_books,
        'genre_counts': genre_counts,
        'genre_finished': genre_finished,
        'monthly_genre': monthly_genre,
        'avg_pace': round(avg_pace, 1),
        'total': len(all_books),
        'finished': sum(1 for b in all_books if b['finished']),
    }


def extract_all_data() -> list[dict]:
    entries = []
    for f in sorted(DIARY_DIR.glob("*.md")):
        m = re.match(r'(\d{4}-\d{2}-\d{2})', f.stem)
        if not m: continue
        date_str = m.group(1)
        text = f.read_text(encoding='utf-8')
        fm = parse_frontmatter(text)

        entry = {'date': date_str}
        
        # Sleep
        sleep_val = fm.get('sleep')
        if sleep_val:
            try:
                entry['hours'] = float(sleep_val)
            except ValueError:
                pass

        # Sleep details from body
        details = parse_sleep_details(text)
        entry.update(details)

        # Exercise from frontmatter
        exercise = parse_exercise(fm)
        if exercise:
            entry['exercise'] = exercise

        # Reading from body
        books = parse_reading(text)
        if books:
            entry['books'] = books

        # Only include if there's meaningful data
        if len(entry) > 1:
            entries.append(entry)

    return entries


# === ç¡çœ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===

def generate_sleep_report(data: list[dict]) -> dict:
    today = datetime.now()
    
    def filter_range(start_date, end_date):
        return [d for d in data if d.get('hours') and start_date <= d['date'] <= end_date]

    this_week_start = (today - timedelta(days=today.weekday())).strftime('%Y-%m-%d')
    this_week_end = today.strftime('%Y-%m-%d')
    last_week_start = (today - timedelta(days=today.weekday() + 7)).strftime('%Y-%m-%d')
    last_week_end = (today - timedelta(days=today.weekday() + 1)).strftime('%Y-%m-%d')
    
    this_month = today.strftime('%Y-%m')
    last_month_dt = today.replace(day=1) - timedelta(days=1)
    last_month = last_month_dt.strftime('%Y-%m')

    this_week = filter_range(this_week_start, this_week_end)
    last_week = filter_range(last_week_start, last_week_end)
    this_month_data = [d for d in data if d.get('hours') and d['date'].startswith(this_month)]
    last_month_data = [d for d in data if d.get('hours') and d['date'].startswith(last_month)]

    def avg(arr): return sum(arr)/len(arr) if arr else 0
    def safe_avg(data_list, key):
        vals = [d[key] for d in data_list if key in d]
        return avg(vals) if vals else None

    report = {
        'generated': today.strftime('%Y-%m-%d %H:%M'),
        'weekly': {},
        'monthly_comparison': {},
        'improvements': [],
        'streaks': {},
    }

    # Weekly
    if this_week:
        wk = report['weekly']
        wk['avg_hours'] = round(avg([d['hours'] for d in this_week]), 2)
        wk['avg_score'] = round(safe_avg(this_week, 'score') or 0, 1)
        wk['days'] = len(this_week)
        wk['best_day'] = max(this_week, key=lambda d: d.get('score', 0)).get('date')
        wk['worst_day'] = min(this_week, key=lambda d: d.get('score', 100)).get('date')
        if last_week:
            lw_avg = avg([d['hours'] for d in last_week])
            wk['vs_last_week'] = round(wk['avg_hours'] - lw_avg, 2)

    # Monthly comparison
    if this_month_data and last_month_data:
        mc = report['monthly_comparison']
        mc['this_month'] = this_month
        mc['last_month'] = last_month
        mc['this_avg_hours'] = round(avg([d['hours'] for d in this_month_data]), 2)
        mc['last_avg_hours'] = round(avg([d['hours'] for d in last_month_data]), 2)
        mc['hours_diff'] = round(mc['this_avg_hours'] - mc['last_avg_hours'], 2)
        
        this_scores = [d['score'] for d in this_month_data if 'score' in d]
        last_scores = [d['score'] for d in last_month_data if 'score' in d]
        if this_scores and last_scores:
            mc['this_avg_score'] = round(avg(this_scores), 1)
            mc['last_avg_score'] = round(avg(last_scores), 1)
            mc['score_diff'] = round(mc['this_avg_score'] - mc['last_avg_score'], 1)
        
        this_deep = [d['deep'] for d in this_month_data if 'deep' in d]
        last_deep = [d['deep'] for d in last_month_data if 'deep' in d]
        if this_deep and last_deep:
            mc['this_avg_deep'] = round(avg(this_deep), 2)
            mc['last_avg_deep'] = round(avg(last_deep), 2)

    # Improvements
    improvements = []
    recent_30 = [d for d in data if d.get('hours') and d['date'] >= (today - timedelta(days=30)).strftime('%Y-%m-%d')]
    
    if recent_30:
        avg_hours = avg([d['hours'] for d in recent_30])
        if avg_hours < 7:
            improvements.append(f"ç›´è¿‘30æ—¥ã®å¹³å‡ç¡çœ ã¯{avg_hours:.1f}hã§ã€æ¨å¥¨ã®7hæœªæº€ã§ã™")
        
        # Check bedtime patterns by day of week
        day_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
        for dow in range(7):
            dow_data = [d for d in recent_30 if d.get('bedtime') and datetime.strptime(d['date'], '%Y-%m-%d').weekday() == dow]
            if len(dow_data) >= 2:
                def to_decimal(t):
                    h, m = map(int, t.split(':'))
                    return (h + 24 if h < 12 else h) + m/60
                avg_bed = avg([to_decimal(d['bedtime']) for d in dow_data])
                if avg_bed > 23.5:
                    improvements.append(f"{day_names[dow]}æ›œæ—¥ã®å¹³å‡å°±å¯ãŒ{int(avg_bed)}:{int((avg_bed%1)*60):02d}ã¨é…ã„å‚¾å‘")
        
        # Deep sleep trend
        recent_deep = [d for d in recent_30 if 'deep' in d]
        if len(recent_deep) >= 14:
            first_half = recent_deep[:len(recent_deep)//2]
            second_half = recent_deep[len(recent_deep)//2:]
            first_avg = avg([d['deep'] for d in first_half])
            second_avg = avg([d['deep'] for d in second_half])
            if second_avg < first_avg * 0.85:
                improvements.append(f"æ·±ã„ç¡çœ ãŒæ¸›å°‘å‚¾å‘ï¼ˆ{first_avg:.1f}hâ†’{second_avg:.1f}hï¼‰")
            elif second_avg > first_avg * 1.15:
                improvements.append(f"æ·±ã„ç¡çœ ãŒæ”¹å–„å‚¾å‘ï¼ˆ{first_avg:.1f}hâ†’{second_avg:.1f}hï¼‰âœ“")
        
        # Score consistency
        scores = [d['score'] for d in recent_30 if 'score' in d]
        if scores:
            low_days = sum(1 for s in scores if s < 85)
            if low_days >= 5:
                improvements.append(f"ç›´è¿‘30æ—¥ã§ã‚¹ã‚³ã‚¢85æœªæº€ãŒ{low_days}æ—¥ã‚ã‚Š")

    report['improvements'] = improvements

    # Streaks
    sleep_data = sorted([d for d in data if d.get('hours')], key=lambda d: d['date'], reverse=True)
    streak_7h = 0
    for d in sleep_data:
        if d['hours'] >= 7:
            streak_7h += 1
        else:
            break
    report['streaks']['days_7h_plus'] = streak_7h

    return report


def generate_obsidian_report(data: list[dict], report: dict) -> str:
    """Obsidianãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    today = datetime.now()
    week_num = today.isocalendar()[1]
    
    lines = [
        f"---",
        f"date: {today.strftime('%Y-%m-%d')}",
        f"type: sleep-report",
        f"tags: [sleep, report, weekly]",
        f"---",
        f"",
        f"# ğŸŒ™ ç¡çœ ãƒ¬ãƒãƒ¼ãƒˆ {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}",
        f"",
    ]

    # Weekly summary
    wk = report.get('weekly', {})
    if wk:
        lines.append("## ğŸ“Š ä»Šé€±ã®å‚¾å‘")
        lines.append(f"- **å¹³å‡ç¡çœ æ™‚é–“**: {wk.get('avg_hours', 'â€”')}h")
        if wk.get('avg_score'):
            lines.append(f"- **å¹³å‡ã‚¹ã‚³ã‚¢**: {wk['avg_score']}")
        if wk.get('vs_last_week') is not None:
            diff = wk['vs_last_week']
            arrow = "â†‘" if diff > 0 else "â†“" if diff < 0 else "â†’"
            lines.append(f"- **å…ˆé€±æ¯”**: {arrow} {abs(diff):.1f}h")
        if wk.get('best_day'):
            lines.append(f"- **ãƒ™ã‚¹ãƒˆ**: {wk['best_day']}")
        lines.append("")

    # Monthly comparison
    mc = report.get('monthly_comparison', {})
    if mc:
        lines.append("## ğŸ“… å…ˆæœˆã¨ã®æ¯”è¼ƒ")
        lines.append(f"| é …ç›® | {mc.get('last_month', '')} | {mc.get('this_month', '')} | å·®åˆ† |")
        lines.append("|---|---|---|---|")
        lines.append(f"| å¹³å‡ç¡çœ  | {mc.get('last_avg_hours', 'â€”')}h | {mc.get('this_avg_hours', 'â€”')}h | {mc.get('hours_diff', 0):+.2f}h |")
        if mc.get('this_avg_score'):
            lines.append(f"| å¹³å‡ã‚¹ã‚³ã‚¢ | {mc.get('last_avg_score', 'â€”')} | {mc.get('this_avg_score', 'â€”')} | {mc.get('score_diff', 0):+.1f} |")
        if mc.get('this_avg_deep'):
            lines.append(f"| æ·±ã„ç¡çœ  | {mc.get('last_avg_deep', 'â€”')}h | {mc.get('this_avg_deep', 'â€”')}h | â€” |")
        lines.append("")

    # Improvements
    if report.get('improvements'):
        lines.append("## ğŸ’¡ æ”¹å–„ç‚¹ãƒ»æ°—ã¥ã")
        for imp in report['improvements']:
            lines.append(f"- {imp}")
        lines.append("")

    # Streaks
    streaks = report.get('streaks', {})
    if streaks.get('days_7h_plus', 0) > 0:
        lines.append(f"## ğŸ”¥ é€£ç¶šè¨˜éŒ²")
        lines.append(f"- 7æ™‚é–“ä»¥ä¸Šã®é€£ç¶šæ—¥æ•°: **{streaks['days_7h_plus']}æ—¥**")
        lines.append("")

    lines.append(f"---")
    lines.append(f"*è‡ªå‹•ç”Ÿæˆ: {report.get('generated', '')}*")
    
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="ç·åˆãƒ©ã‚¤ãƒ•ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    parser.add_argument("--deploy", action="store_true", help="GitHub Pagesã«ãƒ‡ãƒ—ãƒ­ã‚¤")
    args = parser.parse_args()

    print("ğŸ“– æ—¥è¨˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    data = extract_all_data()
    
    has_sleep = [d for d in data if d.get('hours')]
    has_exercise = [d for d in data if d.get('exercise')]
    has_books = [d for d in data if d.get('books')]
    has_steps = [d for d in data if d.get('steps')]

    print(f"   â†’ {len(data)} æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º")
    print(f"      ç¡çœ : {len(has_sleep)}æ—¥ / ç­‹ãƒˆãƒ¬: {len(has_exercise)}æ—¥ / æ­©æ•°: {len(has_steps)}æ—¥ / èª­æ›¸: {len(has_books)}æ—¥")

    # Stats
    if has_sleep:
        hours = [d['hours'] for d in has_sleep]
        scores = [d['score'] for d in has_sleep if 'score' in d]
        print(f"\n   ğŸ“Š ç¡çœ çµ±è¨ˆ:")
        print(f"      å¹³å‡: {sum(hours)/len(hours):.1f}h / æœ€é•·: {max(hours):.1f}h / æœ€çŸ­: {min(hours):.1f}h")
        if scores:
            print(f"      å¹³å‡ã‚¹ã‚³ã‚¢: {sum(scores)/len(scores):.0f}")

    if has_books:
        finished = sum(1 for d in data for b in d.get('books', []) if b.get('finished'))
        print(f"   ğŸ“š èª­äº†: {finished}å†Š")

    # Sleep analysis report
    print("\nğŸ§  ç¡çœ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    report = generate_sleep_report(data)
    
    if report.get('improvements'):
        print("   ğŸ’¡ æ”¹å–„ç‚¹:")
        for imp in report['improvements']:
            print(f"      - {imp}")

    # Generate Obsidian report
    obsidian_md = generate_obsidian_report(data, report)
    report_path = VAULT_DIR / f"ç¡çœ ãƒ¬ãƒãƒ¼ãƒˆ_{datetime.now().strftime('%Y-%m-%d')}.md"
    report_path.write_text(obsidian_md, encoding='utf-8')
    print(f"\nğŸ“ Obsidianãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")

    # Reading summary
    reading_summary = build_reading_summary(data)
    print(f"   ğŸ“š ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥: {', '.join(f'{g}:{c}' for g,c in sorted(reading_summary['genre_counts'].items(), key=lambda x:-x[1]))}")
    print(f"   ğŸ“– å¹³å‡èª­äº†ãƒšãƒ¼ã‚¹: {reading_summary['avg_pace']}æ—¥/å†Š")

    # Generate HTML dashboard
    print("\nğŸ¨ HTMLãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆä¸­...")
    data_json = json.dumps(data, ensure_ascii=False)
    report_json = json.dumps(report, ensure_ascii=False)
    reading_json = json.dumps(reading_summary, ensure_ascii=False)
    
    DOCS_DIR.mkdir(exist_ok=True)
    
    # Read HTML template
    template_path = SCRIPT_DIR / "dashboard_template.html"
    if template_path.exists():
        html = template_path.read_text(encoding='utf-8')
        html = html.replace('__DATA_JSON__', data_json)
        html = html.replace('__REPORT_JSON__', report_json)
        html = html.replace('__READING_JSON__', reading_json)
    else:
        print(f"   âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {template_path}")
        return

    index_path = DOCS_DIR / "index.html"
    index_path.write_text(html, encoding='utf-8')
    print(f"   âœ“ {index_path}")

    # Also save to Vault for local viewing
    vault_html = VAULT_DIR / "ç¡çœ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰.html"
    vault_html.write_text(html, encoding='utf-8')
    print(f"   âœ“ {vault_html}")

    # Generate Sleep App
    print("\nğŸŒ™ ç¡çœ è¨˜éŒ²ã‚¢ãƒ—ãƒªç”Ÿæˆä¸­...")
    sleep_template_path = SCRIPT_DIR / "sleep_template.html"
    if sleep_template_path.exists():
        sleep_data = [d for d in data if d.get('hours') or d.get('score')]
        sleep_json = json.dumps(sleep_data, ensure_ascii=False)
        sleep_html = sleep_template_path.read_text(encoding='utf-8')
        sleep_html = sleep_html.replace('__SLEEP_JSON__', sleep_json)
        sleep_path = DOCS_DIR / "sleep.html"
        sleep_path.write_text(sleep_html, encoding='utf-8')
        print(f"   âœ“ {sleep_path}")
    else:
        print(f"   âš ï¸ ç¡çœ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sleep_template_path}")

    # Deploy
    if args.deploy:
        print("\nğŸš€ GitHub Pagesã«ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­...")
        try:
            subprocess.run(["git", "add", "."], cwd=str(SCRIPT_DIR), check=True)
            subprocess.run(["git", "commit", "-m", f"update {datetime.now().strftime('%Y-%m-%d %H:%M')}"],
                         cwd=str(SCRIPT_DIR), check=True)
            subprocess.run(["git", "push"], cwd=str(SCRIPT_DIR), check=True)
            print("   âœ“ ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ï¼")
        except Exception as e:
            print(f"   âš ï¸ ãƒ‡ãƒ—ãƒ­ã‚¤å¤±æ•—: {e}")
    
    print("\nâœ… å®Œäº†ï¼")


if __name__ == "__main__":
    main()
