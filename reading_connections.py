"""
ğŸ“– èª­æ›¸çŸ¥è­˜é€£çµåˆ†æ
242å†Šã®èª­æ›¸ãƒãƒ¼ãƒˆã‹ã‚‰ã€æœ¬ã¨æœ¬ã®ã¤ãªãŒã‚Šã‚’ç™ºè¦‹ã™ã‚‹
- æ„Ÿæƒ³ãƒ»æ°—ã¥ãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å…±é€šãƒ†ãƒ¼ãƒã‚’æŠ½å‡º
- ã‚¸ãƒ£ãƒ³ãƒ«æ¨ªæ–­ã®æ„å¤–ãªã¤ãªãŒã‚Šã‚’è¦‹ã¤ã‘ã‚‹
- è‘—è€…ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')

from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
import re, yaml

VAULT_DIR = Path(r"C:\Documents\Obsidian Vault\Main Vault")
BOOK_DIR = VAULT_DIR / "ğŸ“š_èª­æ›¸ãƒ¡ãƒ¢"


def parse_book(filepath):
    """1å†Šã®èª­æ›¸ãƒãƒ¼ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦è¾æ›¸ã‚’è¿”ã™"""
    text = filepath.read_text(encoding='utf-8')
    book = {
        'file': filepath,
        'link': filepath.stem,
        'title': filepath.stem.split(' - ')[0].strip(),
        'author': '',
        'category': '',
        'review': '',
        'learning': '',
        'quotes': '',
        'finished': '',
    }
    
    # Frontmatter
    fm_match = re.match(r'^---\n(.*?)\n---', text, re.DOTALL)
    if fm_match:
        try:
            fm = yaml.safe_load(fm_match.group(1))
            authors = fm.get('author', [])
            if isinstance(authors, list):
                book['author'] = ', '.join(str(a) for a in authors if a)
            else:
                book['author'] = str(authors) if authors else ''
            
            cat = fm.get('category', [])
            if isinstance(cat, list):
                book['category'] = ', '.join(str(c) for c in cat if c)
            else:
                book['category'] = str(cat) if cat else ''
            
            book['finished'] = str(fm.get('èª­äº†æ—¥', ''))
        except:
            pass
    
    # Content sections
    review = re.search(r'æ„Ÿæƒ³\s*\n+(.*?)(?=\n---|\n######|\Z)', text, re.DOTALL)
    learning = re.search(r'æ°—ã¥ããƒ»å­¦ã³\s*\n+(.*?)(?=\n---|\n######|\Z)', text, re.DOTALL)
    quotes = re.search(r'(?:å°è±¡ã«æ®‹ã£ãŸãƒ•ãƒ¬ãƒ¼ã‚º|å¼•ç”¨)\s*\n+(.*?)(?=\n---|\n######|\Z)', text, re.DOTALL)
    
    if review:
        t = review.group(1).strip()
        if t not in ('', '-', '- '):
            book['review'] = t
    if learning:
        t = learning.group(1).strip()
        if t not in ('', '-', '- '):
            book['learning'] = t
    if quotes:
        t = quotes.group(1).strip()
        if t not in ('', '-', '- ', '>', '> '):
            book['quotes'] = t
    
    book['all_text'] = ' '.join([book['review'], book['learning'], book['quotes']])
    return book


# ãƒ†ãƒ¼ãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ï¼ˆæ—¥æœ¬èª â†’ ãƒ†ãƒ¼ãƒï¼‰
THEME_KEYWORDS = {
    'ç¡çœ ': ['ç¡çœ ', 'çœ ', 'ä¸çœ ', 'å°±å¯', 'è¦šé†’', 'å®‰çœ ', 'ç›®è¦šã‚', 'å¤œä¸­'],
    'äººé–“ã®æœ¬è³ª': ['äººé–“', 'äººé–“æ€§', 'æœ¬è³ª', 'æœ¬èƒ½', 'æ¬²æœ›', 'å¼±ã•', 'é—‡', 'å¿ƒç†', 'çœŸç†', 'å“²å­¦'],
    'æˆé•·ãƒ»å­¦ã³': ['å­¦ã³', 'æˆé•·', 'å‹‰å¼·', 'åŠªåŠ›', 'æŒ‘æˆ¦', 'ç¶™ç¶š', 'ç¿’æ…£', 'ç·´ç¿’', 'ã‚¹ã‚­ãƒ«', 'ä¸Šé”', 'å­¦ç¿’'],
    'äººé–“é–¢ä¿‚': ['äººé–“é–¢ä¿‚', 'ä¿¡é ¼', 'å‹æƒ…', 'å®¶æ—', 'è¦ªå­', 'æ‹æ„›', 'çµ†', 'å­¤ç‹¬', 'è£åˆ‡ã‚Š', 'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³'],
    'ç”Ÿã¨æ­»': ['æ­»', 'ç”Ÿãã‚‹', 'å‘½', 'äººç”Ÿ', 'æ­»ç”Ÿè¦³', 'è¦šæ‚Ÿ', 'ç„¡å¸¸', 'é‹å‘½'],
    'ç¤¾ä¼šãƒ»åˆ¶åº¦': ['ç¤¾ä¼š', 'æ”¿æ²»', 'æ³•å¾‹', 'åˆ¶åº¦', 'æ ¼å·®', 'å·®åˆ¥', 'æ¨©åŠ›', 'çµ„ç¹”', 'è³‡æœ¬', 'çµŒæ¸ˆ'],
    'æ—¥æœ¬æ–‡åŒ–': ['æ—¥æœ¬', 'æ–‡åŒ–', 'æ­´å²', 'ä¼çµ±', 'ä»æ•™', 'ç¦…', 'æ­¦å£«', 'å¤ä»£', 'è¿‘ä»£'],
    'å¥åº·ãƒ»èº«ä½“': ['å¥åº·', 'é‹å‹•', 'ç­‹ãƒˆãƒ¬', 'ä½“', 'ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°', 'é£Ÿäº‹', 'æ „é¤Š', 'èº«ä½“', 'ã‚¹ãƒˆãƒ¬ã‚¹'],
    'ä»•äº‹ãƒ»ãƒ“ã‚¸ãƒã‚¹': ['ä»•äº‹', 'ãƒ“ã‚¸ãƒã‚¹', 'ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—', 'çµŒå–¶', 'å–¶æ¥­', 'ç”Ÿç”£æ€§', 'ã‚­ãƒ£ãƒªã‚¢'],
    'çŸ¥è­˜ãƒ»æ€è€ƒ': ['æ€è€ƒ', 'çŸ¥è­˜', 'å“²å­¦', 'ç§‘å­¦', 'è«–ç†', 'åˆ†æ', 'çŸ¥æ€§', 'èªçŸ¥', 'AI', 'ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼'],
    'ç‰©èªã®åŠ›': ['ç‰©èª', 'å°èª¬', 'ãƒŸã‚¹ãƒ†ãƒªãƒ¼', 'æ¨ç†', 'ãƒˆãƒªãƒƒã‚¯', 'ä¼ç·š', 'å™è¿°', 'é©šã', 'çŠ¯äºº', 'å‹•æ©Ÿ'],
    'è‡ªç”±ãƒ»ç”Ÿãæ–¹': ['è‡ªç”±', 'ç”Ÿãæ–¹', 'é¸æŠ', 'æ±ºæ–­', 'ä¾¡å€¤è¦³', 'å¹¸ç¦', 'å¹¸ã›', 'å……å®Ÿ', 'ã‚„ã‚ŠãŸã„ã“ã¨'],
    'è¨˜éŒ²ãƒ»ãƒãƒ¼ãƒˆ': ['è¨˜éŒ²', 'ãƒãƒ¼ãƒˆ', 'ãƒ¡ãƒ¢', 'æ—¥è¨˜', 'æ›¸ã', 'æ–‡ç« ', 'èª­æ›¸', 'èª­ã‚€', 'è¨€è‘‰', 'è¨˜æ†¶'],
}


def find_themes(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ†ãƒ¼ãƒã‚’æ¤œå‡º"""
    found = []
    for theme, keywords in THEME_KEYWORDS.items():
        score = sum(1 for kw in keywords if kw in text)
        if score >= 2:
            found.append((theme, score))
    found.sort(key=lambda x: -x[1])
    return found


def analyze():
    print("ğŸ“– èª­æ›¸çŸ¥è­˜é€£çµåˆ†æä¸­...\n")
    
    files = sorted(BOOK_DIR.glob('*.md'))
    books = []
    for f in files:
        if f.name.startswith('00_'):
            continue
        b = parse_book(f)
        if b['all_text'].strip():
            books.append(b)
    
    print(f"  ğŸ“š åˆ†æå¯¾è±¡: {len(books)}å†Šï¼ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚ã‚Šï¼‰\n")
    
    # â”€â”€â”€ 1. ãƒ†ãƒ¼ãƒåˆ†æ â”€â”€â”€
    theme_books = defaultdict(list)
    for b in books:
        themes = find_themes(b['all_text'])
        b['themes'] = themes
        for theme, score in themes:
            theme_books[theme].append((b, score))
    
    # Sort themes by book count
    theme_ranking = sorted(theme_books.items(), key=lambda x: -len(x[1]))
    
    # â”€â”€â”€ 2. ã‚¸ãƒ£ãƒ³ãƒ«æ¨ªæ–­ã¤ãªãŒã‚Š â”€â”€â”€
    cross_genre = []
    for theme, theme_book_list in theme_ranking:
        genres_in_theme = set()
        for b, _ in theme_book_list:
            genres_in_theme.add(b['category'].split(',')[0].strip() if b['category'] else 'Unknown')
        if len(genres_in_theme) >= 3:
            cross_genre.append((theme, theme_book_list, genres_in_theme))
    
    # â”€â”€â”€ 3. è‘—è€…åˆ¥ãƒ†ãƒ¼ãƒå¤šæ§˜æ€§ â”€â”€â”€
    author_books = defaultdict(list)
    for b in books:
        if b['author']:
            for a in b['author'].split(','):
                a = a.strip()
                if a:
                    author_books[a].append(b)
    
    multi_book_authors = {a: bks for a, bks in author_books.items() if len(bks) >= 3}
    
    # â”€â”€â”€ 4. æ™‚ç³»åˆ—ãƒ†ãƒ¼ãƒå¤‰é· â”€â”€â”€
    monthly_themes = defaultdict(lambda: Counter())
    for b in books:
        if b['finished'] and b['finished'] != 'None':
            month = b['finished'][:7]
            if month and len(month) == 7:
                for theme, score in b.get('themes', []):
                    monthly_themes[month][theme] += score
    
    # â”€â”€â”€ Generate Report â”€â”€â”€
    md = f"""---
tags: [è‡ªå·±åˆ†æ, èª­æ›¸, çŸ¥è­˜é€£çµ]
generated: {datetime.now().strftime('%Y-%m-%d')}
---

# ğŸ“– èª­æ›¸çŸ¥è­˜é€£çµãƒãƒƒãƒ—

> **{len(books)}å†Š**ã®æ„Ÿæƒ³ãƒ»æ°—ã¥ããƒ»å¼•ç”¨ã‹ã‚‰ã€ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¶…ãˆãŸãƒ†ãƒ¼ãƒã®ã¤ãªãŒã‚Šã‚’å¯è¦–åŒ–

## ğŸ—ºï¸ ã‚ãªãŸã®èª­æ›¸ã‚’è²«ããƒ†ãƒ¼ãƒ TOP10

"""
    print("  ğŸ—ºï¸ ãƒ†ãƒ¼ãƒ TOP10:")
    for i, (theme, tbooks) in enumerate(theme_ranking[:10], 1):
        top_books = sorted(tbooks, key=lambda x: -x[1])[:5]
        md += f"### {i}. {theme}ï¼ˆ{len(tbooks)}å†Šï¼‰\n\n"
        md += f"ä»£è¡¨çš„ãªæœ¬: {', '.join(b['title'][:25] for b, _ in top_books)}\n\n"
        print(f"    {i}. {theme}: {len(tbooks)}å†Š")
    
    # Cross-genre connections
    md += "\n## ğŸ”— ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¶…ãˆãŸã¤ãªãŒã‚Š\n\n"
    md += "> å…¨ãé•ã†ã‚¸ãƒ£ãƒ³ãƒ«ã®æœ¬ãªã®ã«ã€å…±é€šãƒ†ãƒ¼ãƒã§ç¹‹ãŒã£ã¦ã„ã‚‹çµ„ã¿åˆã‚ã›\n\n"
    
    print("\n  ğŸ”— ã‚¸ãƒ£ãƒ³ãƒ«æ¨ªæ–­ç™ºè¦‹:")
    for theme, tbooks, genres in cross_genre[:5]:
        md += f"### ã€Œ{theme}ã€ã§ç¹‹ãŒã‚‹æœ¬ãŸã¡\n\n"
        md += f"*{len(genres)}ã‚¸ãƒ£ãƒ³ãƒ«ã‹ã‚‰{len(tbooks)}å†ŠãŒé›†çµ*\n\n"
        
        # Group by genre
        by_genre = defaultdict(list)
        for b, score in tbooks:
            g = b['category'].split(',')[0].strip() if b['category'] else 'Unknown'
            by_genre[g].append(b)
        
        for genre, genre_books in sorted(by_genre.items(), key=lambda x: -len(x[1])):
            titles = ', '.join(b['title'][:30] for b in genre_books[:3])
            md += f"- **{genre}**: {titles}\n"
        
        # Show interesting quote if available
        quoted = [b for b, _ in tbooks if b['quotes']]
        if quoted:
            snippet = quoted[0]['quotes'][:150].replace('\n', ' ')
            md += f"\n> ğŸ’¬ {quoted[0]['title'][:20]}ã‚ˆã‚Š:\n> {snippet}...\n"
        
        md += "\n---\n\n"
        print(f"    ã€Œ{theme}ã€: {len(tbooks)}å†Š Ã— {len(genres)}ã‚¸ãƒ£ãƒ³ãƒ«")
    
    # Author analysis
    if multi_book_authors:
        md += "\n## âœï¸ ã‚ˆãèª­ã‚€è‘—è€…ã¨ãã®ãƒ†ãƒ¼ãƒ\n\n"
        print("\n  âœï¸ å¤šèª­è‘—è€…:")
        for author, auth_books in sorted(multi_book_authors.items(), key=lambda x: -len(x[1]))[:8]:
            all_themes = Counter()
            for b in auth_books:
                for theme, score in b.get('themes', []):
                    all_themes[theme] += score
            
            top_themes = [t for t, _ in all_themes.most_common(3)]
            
            md += f"### {author}ï¼ˆ{len(auth_books)}å†Šï¼‰\n\n"
            md += f"ãƒ†ãƒ¼ãƒå‚¾å‘: {', '.join(top_themes) if top_themes else 'ï¼ˆãƒ†ãƒ¼ãƒæœªåˆ†é¡ï¼‰'}\n\n"
            md += f"èª­ã‚“ã æœ¬: {', '.join(b['title'][:25] for b in auth_books[:5])}\n\n"
            print(f"    {author}: {len(auth_books)}å†Š â†’ {', '.join(top_themes[:2]) if top_themes else '-'}")
    
    # Monthly theme evolution
    if monthly_themes:
        md += "\n## ğŸ“… ãƒ†ãƒ¼ãƒã®æ™‚ç³»åˆ—å¤‰é·\n\n"
        md += "| æœˆ | ä¸»è¦ãƒ†ãƒ¼ãƒ |\n|---|---|\n"
        for month in sorted(monthly_themes.keys()):
            top = monthly_themes[month].most_common(3)
            themes_str = ', '.join(f'{t}' for t, _ in top)
            md += f"| {month} | {themes_str} |\n"
    
    # Key insight
    md += f"""

## ğŸ’¡ ã‚ãªãŸã®èª­æ›¸ã‹ã‚‰è¦‹ãˆã‚‹ã‚‚ã®

"""
    # Calculate dominant themes
    all_theme_counts = Counter()
    for b in books:
        for theme, score in b.get('themes', []):
            all_theme_counts[theme] += score
    
    top3 = all_theme_counts.most_common(3)
    if top3:
        md += f"ã‚ãªãŸã®èª­æ›¸ã‚’æœ€ã‚‚å¼·ãè²«ããƒ†ãƒ¼ãƒã¯ **ã€Œ{top3[0][0]}ã€ã€Œ{top3[1][0]}ã€ã€Œ{top3[2][0]}ã€** ã§ã™ã€‚\n\n"
        md += "ãƒŸã‚¹ãƒ†ãƒªãƒ¼ã‚’æ¥½ã—ã¿ãªãŒã‚‰ã‚‚ã€å®Ÿã¯ã€Œäººé–“ã¨ã¯ä½•ã‹ã€ã€Œã©ã†ç”Ÿãã‚‹ã‹ã€ã¨ã„ã†å•ã„ãŒé€šåº•ã—ã¦ã„ã¾ã™ã€‚\n\n"
    
    md += f"\n*è‡ªå‹•ç”Ÿæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n"
    
    report_path = VAULT_DIR / "èª­æ›¸çŸ¥è­˜é€£çµãƒãƒƒãƒ—.md"
    report_path.write_text(md, encoding='utf-8')
    print(f"\n  âœ“ ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    print("\nâœ… å®Œäº†ï¼")


if __name__ == "__main__":
    analyze()
